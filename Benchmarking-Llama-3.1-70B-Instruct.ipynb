{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc561d7",
   "metadata": {},
   "source": [
    "### 4 bit quantized Llama-3.1-70B-Instruct: Few-shot prompting given domain context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded80675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from utils import *\n",
    "from openai import RateLimitError\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "# model name and/or local path to model\n",
    "model_name = \"Llama-3.1-70B-Instruct-bnb-4bit\"\n",
    "# Change this to local path or model name on huggingface\n",
    "model_path = \"/mimer/NOBACKUP/Datasets/LLM/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-Instruct-bnb-4bit/snapshots/d401984d962a6cbeba8514c16409f9631e72d2c1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                             dtype = torch.bfloat16,\n",
    "                                             use_cache = True,\n",
    "                                             device_map = \"auto\",\n",
    "                                             quantization_config = bnb_config\n",
    ")\n",
    "\n",
    "# Create messages\n",
    "\n",
    "data_path = os.path.join('data', 'transformed_data.txt')\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "system_message_path = os.path.join(\"data\", \"system_message_context.txt\")\n",
    "with open(system_message_path, \"r\") as f:\n",
    "    system_txt = f.read().strip()\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": system_txt}\n",
    "\n",
    "# Randomly sample n lines for training and N lines for testing\n",
    "n = 10\n",
    "N = 25\n",
    "\n",
    "# Initialize empty lists to store results\n",
    "result_list = []\n",
    "indices = list(range(len(data)))\n",
    "# Repeat the process 10 times\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    #np.random.seed(i)\n",
    "    test_prompts, true_values, predictions = gather_LLM_results(data,\n",
    "                                                                n,\n",
    "                                                                N,\n",
    "                                                                None,\n",
    "                                                                model_name,\n",
    "                                                                indices,\n",
    "                                                                system_message,\n",
    "                                                                None,\n",
    "                                                                model,\n",
    "                                                                tokenizer)\n",
    "\n",
    "    append_to_result_list(test_prompts, true_values, predictions, result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5adad82-8b2a-4361-903c-b9b266ac098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 250 iterations are saved to a single CSV file.\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "save_results_to_csv(model_name, \"ICL_finetuned\",  result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a475b6",
   "metadata": {},
   "source": [
    "### Llama-3.2-3B-Instruct: few-shot prompting without domain context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acff497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from utils import *\n",
    "from openai import RateLimitError\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "# model name and/or local path to model\n",
    "model_name = \"Llama-3.1-70B-Instruct-bnb-4bit\"\n",
    "# Change this to local path or model name on huggingface\n",
    "model_path = \"/mimer/NOBACKUP/Datasets/LLM/huggingface/hub/models--unsloth--Meta-Llama-3.1-70B-Instruct-bnb-4bit/snapshots/d401984d962a6cbeba8514c16409f9631e72d2c1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                             dtype = torch.bfloat16,\n",
    "                                             use_cache = True,\n",
    "                                             device_map = \"auto\",\n",
    "                                             quantization_config = bnb_config\n",
    ")\n",
    "\n",
    "# Create messages\n",
    "\n",
    "data_path = os.path.join('data', 'transformed_data.txt')\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "system_message_path = os.path.join(\"data\", \"system_message.txt\")\n",
    "with open(system_message_path, \"r\") as f:\n",
    "    system_txt = f.read().strip()\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": system_txt}\n",
    "\n",
    "# Randomly sample n lines for training and N lines for testing\n",
    "n = 10\n",
    "N = 25\n",
    "\n",
    "# Initialize empty lists to store results\n",
    "result_list = []\n",
    "indices = list(range(len(data)))\n",
    "# Repeat the process 10 times\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    #np.random.seed(i)\n",
    "    test_prompts, true_values, predictions = gather_LLM_results(data,\n",
    "                                                                n,\n",
    "                                                                N,\n",
    "                                                                None,\n",
    "                                                                model_name,\n",
    "                                                                indices,\n",
    "                                                                system_message,\n",
    "                                                                None,\n",
    "                                                                model,\n",
    "                                                                tokenizer)\n",
    "\n",
    "    append_to_result_list(test_prompts, true_values, predictions, result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e968715f-4086-4c02-8727-5786d712217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 250 iterations are saved to a single CSV file.\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "\n",
    "save_results_to_csv(model_name, \"ICL\", result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b2530",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression (GPR)\n",
    "\n",
    "In this section, we will benchmark the performance of the Gaussian Process Regression (GPR) model using the `scikit-learn` library. GPR is a non-parametric, Bayesian approach to regression that provides uncertainty estimates of the predictions. It is based on the assumption that any finite set of data points can be modeled by a multivariate Gaussian distribution.\n",
    "\n",
    "All training and test sets used for the experiments will be stored in the `results` folder, allowing for easy access and reproducibility of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b166d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "R-squared: 0.78\n",
      "MAE: 4.35\n",
      "MSE: 29.76\n",
      "Iteration: 2\n",
      "R-squared: 0.01\n",
      "MAE: 8.30\n",
      "MSE: 100.57\n",
      "Iteration: 3\n",
      "R-squared: 0.62\n",
      "MAE: 4.34\n",
      "MSE: 28.64\n",
      "Iteration: 4\n",
      "R-squared: 0.35\n",
      "MAE: 6.41\n",
      "MSE: 59.51\n",
      "Iteration: 5\n",
      "R-squared: 0.28\n",
      "MAE: 7.41\n",
      "MSE: 80.64\n",
      "Iteration: 6\n",
      "R-squared: 0.64\n",
      "MAE: 4.89\n",
      "MSE: 31.87\n",
      "Iteration: 7\n",
      "R-squared: 0.78\n",
      "MAE: 4.45\n",
      "MSE: 30.08\n",
      "Iteration: 8\n",
      "R-squared: 0.69\n",
      "MAE: 4.66\n",
      "MSE: 30.84\n",
      "Iteration: 9\n",
      "R-squared: 0.48\n",
      "MAE: 6.17\n",
      "MSE: 59.95\n",
      "Iteration: 10\n",
      "R-squared: 0.65\n",
      "MAE: 5.70\n",
      "MSE: 45.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.5578529/ipykernel_247744/2811472177.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_results_df = pd.concat([test_results_df, iteration_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern\n",
    "\n",
    "\n",
    "#data = pd.read_csv(r'data/numeric_data.csv')\n",
    "file_path = os.path.join('data', 'numeric_data.csv')\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "kernel = ConstantKernel(1.0, (1e-3, 1e3)) * Matern(length_scale=10, nu=1.5)\n",
    "\n",
    "gpr = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# DataFrames to store results\n",
    "train_results_df = pd.DataFrame()\n",
    "test_results_df = pd.DataFrame(columns=['Iteration', 'Idx_Sample', 'Input Features', 'True Values', 'Predicted Values'])\n",
    "\n",
    "n = 10\n",
    "N = 25\n",
    "\n",
    "indices = list(range(len(data)))\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    #np.random.seed(i)\n",
    "    #random_indices = np.random.choice(len(data), n+N, False)\n",
    "    random.shuffle(indices)\n",
    "    # Sample the data based on the provided indices\n",
    "    train_data = data.iloc[indices[:n]]\n",
    "    test_data = data.iloc[indices[n:n+N]]\n",
    "\n",
    "    target_column = 'fc_28dGroundTruth'\n",
    "    idx_column = 'Idx_Sample'\n",
    "    X_train = train_data.drop(columns=[target_column, idx_column], axis=1)\n",
    "\n",
    "    # Normalize input features\n",
    "    X_scaler = StandardScaler()\n",
    "    X_train = X_scaler.fit_transform(X_train)\n",
    "\n",
    "    # Scale the target variable for training\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_train = y_scaler.fit_transform(train_data[target_column].copy().to_numpy().reshape(-1, 1))\n",
    "\n",
    "    gpr.fit(X_train, y_train)\n",
    "\n",
    "    # Test data\n",
    "    X_test = test_data.drop(columns=[target_column, idx_column], axis=1)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "\n",
    "    # Predict on test data\n",
    "    predictions = gpr.predict(X_test)\n",
    "    predictions = predictions.reshape(-1, 1)\n",
    "    predictions = y_scaler.inverse_transform(predictions)\n",
    "\n",
    "    # Store true and predicted values\n",
    "    true_values = test_data[target_column].copy().to_numpy().reshape(-1, 1)\n",
    "    idx_sample = test_data[idx_column].copy().to_numpy()\n",
    "\n",
    "    # Store train data\n",
    "    \n",
    "    train_results_df = pd.concat([train_results_df, train_data], ignore_index=True)\n",
    "\n",
    "    # Store test data\n",
    "    iteration_df = pd.DataFrame({\n",
    "        'Iteration': i+1,\n",
    "        'Idx_Sample': idx_sample,\n",
    "        'Input Features': list(X_test),\n",
    "        'True Values': true_values.flatten(),\n",
    "        'Predicted Values': predictions.flatten()\n",
    "    })\n",
    "\n",
    "    test_results_df = pd.concat([test_results_df, iteration_df], ignore_index=True)\n",
    "\n",
    "    # Calculate R2 score and mean absolute error\n",
    "    r2 = r2_score(true_values, predictions)\n",
    "    mae = mean_absolute_error(true_values, predictions)   \n",
    "    mse = mean_squared_error(true_values, predictions)\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"Iteration: {i+1}\")\n",
    "    print(f\"R-squared: {r2:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "\n",
    "\n",
    "train_results_file = os.path.join('results', model_name, 'GPR', 'train.csv')\n",
    "\n",
    "# Make needed directories\n",
    "dir_name = os.path.dirname(train_results_file)\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "train_results_df.to_csv(train_results_file, index=False)\n",
    "\n",
    "test_results_file = os.path.join('results', model_name, 'GPR', 'test.csv')\n",
    "test_results_df.to_csv(test_results_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08adf38",
   "metadata": {},
   "source": [
    "### Random Forest (M5-Tree with Linear Tree Models)\n",
    "\n",
    "In this section, we will benchmark the performance of the Random Forest (RF) model using an M5-Tree with linear tree models and well-calibrated uncertainty estimates, implemented in the `lolopy` library. RF is an ensemble learning method that constructs multiple decision trees and combines their output for improved prediction accuracy and reduced overfitting. The M5-Tree with linear tree models enhances the standard RF by incorporating linear regression models in the tree leaves, providing better performance on certain types of data. \n",
    "\n",
    "EDIT: No longer uses 'lolopy' library\n",
    "\n",
    "All training and test sets used for the experiments will be stored in the `results` folder, allowing for easy access and reproducibility of the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9930c9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/local/tmp.5578529/ipykernel_247744/3119805488.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_results_df = pd.concat([test_results_df, iteration_df], ignore_index=True)\n",
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "R-squared: 0.63\n",
      "MAE: 5.76\n",
      "MSE: 50.06\n",
      "Iteration: 2\n",
      "R-squared: 0.66\n",
      "MAE: 5.04\n",
      "MSE: 34.32\n",
      "Iteration: 3\n",
      "R-squared: 0.49\n",
      "MAE: 4.68\n",
      "MSE: 38.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4\n",
      "R-squared: 0.46\n",
      "MAE: 5.91\n",
      "MSE: 49.23\n",
      "Iteration: 5\n",
      "R-squared: 0.63\n",
      "MAE: 5.27\n",
      "MSE: 41.04\n",
      "Iteration: 6\n",
      "R-squared: 0.62\n",
      "MAE: 4.55\n",
      "MSE: 33.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7\n",
      "R-squared: 0.71\n",
      "MAE: 5.10\n",
      "MSE: 39.54\n",
      "Iteration: 8\n",
      "R-squared: 0.59\n",
      "MAE: 5.13\n",
      "MSE: 40.12\n",
      "Iteration: 9\n",
      "R-squared: 0.45\n",
      "MAE: 6.13\n",
      "MSE: 63.85\n",
      "Iteration: 10\n",
      "R-squared: 0.54\n",
      "MAE: 6.21\n",
      "MSE: 59.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.12/site-packages/sklearn/base.py:1336: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "file_path = os.path.join('data', 'numeric_data.csv')\n",
    "data = pd.read_csv(file_path)  \n",
    "        \n",
    "\n",
    "# DataFrames to store results\n",
    "train_results_df = pd.DataFrame()\n",
    "test_results_df = pd.DataFrame(columns=['Iteration', 'Idx_Sample', 'Input Features', 'True Values', 'Predicted Values'])\n",
    "\n",
    "n = 10\n",
    "N = 25\n",
    "\n",
    "indices = list(range(len(data)))\n",
    "\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    # np.random.seed(i)\n",
    "\n",
    "    #random_indices = np.random.choice(len(data), n+N, False)\n",
    "    random.shuffle(indices)\n",
    "    # Sample the data based on the provided indices\n",
    "    train_data = data.iloc[indices[:n]]\n",
    "    test_data = data.iloc[indices[n:n+N]]\n",
    "\n",
    "    target_column = 'fc_28dGroundTruth'\n",
    "    idx_column = 'Idx_Sample'\n",
    "    X_train = train_data.drop(columns=[target_column, idx_column], axis=1)\n",
    "\n",
    "    # Normalize input features\n",
    "    X_scaler = StandardScaler()\n",
    "    X_train = X_scaler.fit_transform(X_train)\n",
    "\n",
    "    # Scale the target variable for training\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_train = y_scaler.fit_transform(train_data[target_column].copy().to_numpy().reshape(-1, 1))\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Test data\n",
    "    X_test = test_data.drop(columns=[target_column, idx_column], axis=1)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "\n",
    "    # Predict on test data\n",
    "    predictions = rf.predict(X_test)\n",
    "    predictions = predictions.reshape(-1, 1)\n",
    "    predictions = y_scaler.inverse_transform(predictions)\n",
    "\n",
    "    # Store true and predicted values\n",
    "    true_values = test_data[target_column].copy().to_numpy().reshape(-1, 1)\n",
    "    idx_sample = test_data[idx_column].copy().to_numpy()\n",
    "\n",
    "    # Store train data\n",
    "    #train_results_df = train_results_df.append(train_data)\n",
    "    train_results_df = pd.concat([train_results_df, train_data], ignore_index=True)\n",
    "\n",
    "    # Store test data\n",
    "    iteration_df = pd.DataFrame({\n",
    "        'Iteration': i+1,\n",
    "        'Idx_Sample': idx_sample,\n",
    "        'Input Features': list(X_test),\n",
    "        'True Values': true_values.flatten(),\n",
    "        'Predicted Values': predictions.flatten()\n",
    "    })\n",
    "\n",
    "    test_results_df = pd.concat([test_results_df, iteration_df], ignore_index=True)\n",
    "\n",
    "    # Calculate R2 score and mean absolute error\n",
    "    r2 = r2_score(true_values, predictions)\n",
    "    mae = mean_absolute_error(true_values, predictions)   \n",
    "    mse = mean_squared_error(true_values, predictions)\n",
    "\n",
    "    # Evaluation\n",
    "    print(f\"Iteration: {i+1}\")\n",
    "    print(f\"R-squared: {r2:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "\n",
    "\n",
    "train_results_file = os.path.join('results', model_name, 'RF', 'train.csv')\n",
    "\n",
    "dir_name = os.path.dirname(train_results_file)\n",
    "os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "train_results_df.to_csv(train_results_file, index=False)\n",
    "\n",
    "test_results_file = os.path.join('results', model_name, 'RF', 'test.csv')\n",
    "test_results_df.to_csv(test_results_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
